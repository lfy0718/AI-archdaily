# agent_planning_app.py
import gradio as gr
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import re
import json
from typing import List, Tuple, Dict
import os

# æ–°å¢å¯¼å…¥
from openai import OpenAI

from apis import cn_clip_api
from config import *


# è¯»å–image_database.pklæ–‡ä»¶
def load_database():
    pkl_path = 'results/database/image_database.pkl'
    if not os.path.exists(pkl_path):
        # åˆ›å»ºç¤ºä¾‹æ•°æ®ä»¥é˜²æ•°æ®åº“ä¸å­˜åœ¨
        return pd.DataFrame({
            'project_id': [],
            'features': [],
            'image_path': [],
            'tags': []
        })

    df = pd.read_pickle(pkl_path)

    # è¿‡æ»¤å¹¶å±•å¹³å‘é‡
    df = df[df['features'].apply(lambda x: isinstance(x, np.ndarray))]
    df['features'] = df['features'].apply(
        lambda x: x.squeeze() if x.ndim > 1 else x  # å»é™¤å•ç»´åº¦
    )
    return df


# åœ¨ç¨‹åºå¯åŠ¨æ—¶åŠ è½½DataFrame
try:
    df = load_database()
    if len(df) > 0:
        image_features: np.ndarray = np.stack(df['features'].values)
    else:
        image_features = np.array([])
except Exception as e:
    print(f"åŠ è½½æ•°æ®åº“æ—¶å‡ºé”™: {e}")
    df = pd.DataFrame({
        'project_id': [],
        'features': [],
        'image_path': [],
        'tags': []
    })
    image_features = np.array([])

print(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æœ‰æ•ˆæ•°æ®")


# è®¡ç®—æ–‡æœ¬ç‰¹å¾å‘é‡
def compute_text_features(text):
    if not text:
        return None
    # è®¡ç®—ç‰¹å¾å‘é‡
    feature_vector = cn_clip_api.get_text_features(text)

    # ç¡®ä¿ feature_vector æ˜¯äºŒç»´æ•°ç»„
    if feature_vector.ndim == 1:
        feature_vector = feature_vector.reshape(1, -1)
    return feature_vector


# ä»ç”¨æˆ·è¾“å…¥ä¸­æå–è®¾è®¡è¦ç‚¹
def extract_design_points(user_input: str) -> List[str]:
    """
    ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å…³é”®è®¾è®¡è¦ç‚¹
    """
    # å…³é”®è¯æ¨¡å¼
    patterns = [
        r"(\d+\s*ä¸ªç­)",
        r"(å°å­¦|ä¸­å­¦|å¹¼å„¿å›­|å¤§å­¦|å­¦é™¢)",
        r"(å±±è„š|å±±å¡|å±±é¡¶|æµ·è¾¹|åŸå¸‚|éƒŠåŒº|ä¹¡æ‘)",
        r"(ç°ä»£|ä¼ ç»Ÿ|ç®€çº¦|æ¬§å¼|ä¸­å¼|æ—¥å¼|ç¾å¼|å·¥ä¸šé£)",
        r"(\d+\s*(å¹³æ–¹ç±³|å¹³ç±³|ã¡|å…¬é¡·))",
        r"(ç»¿è‰²|ç¯ä¿|å¯æŒç»­|èŠ‚èƒ½|å¤ªé˜³èƒ½|é›¨æ°´æ”¶é›†)",
        r"(å¼€æ”¾å¼|å°é—­å¼|åº­é™¢|å¤©äº•|ä¸­åº­)",
        r"(\d+\s*(å±‚|æ¥¼))",
        r"(å¤šåŠŸèƒ½|å¤åˆ|ç»¼åˆ|ä¸€ä½“åŒ–)",
        r"(æ™¯è§‚|ç»¿åŒ–|èŠ±å›­|å…¬å›­|åº­é™¢)"
    ]

    design_points = []
    for pattern in patterns:
        matches = re.findall(pattern, user_input, re.IGNORECASE)
        design_points.extend(matches)

    # æ·»åŠ æ•´ä¸ªè¾“å…¥ä½œä¸ºå¤‡é€‰
    if not design_points:
        design_points.append(user_input)

    return design_points


# æå–å…³é”®è¯
def extract_keywords(design_points: List[str]) -> List[str]:
    """
    ä»è®¾è®¡è¦ç‚¹ä¸­æå–å…³é”®è¯ç”¨äºæ£€ç´¢
    """
    keywords = []
    for point in design_points:
        # ç®€å•åˆ†è¯
        words = re.findall(r'\w+', point.lower())
        keywords.extend(words)
    return list(set(keywords))  # å»é‡


# åŒ¹é…æœ€ç›¸ä¼¼çš„é¡¹ç›®
def find_similar_items(text_feature_vectors: List[np.ndarray],
                       df: pd.DataFrame,
                       image_features: np.ndarray,
                       top_k: int = 5) -> pd.DataFrame:
    """
    æ ¹æ®å¤šä¸ªæ–‡æœ¬ç‰¹å¾å‘é‡æ£€ç´¢æœ€ç›¸ä¼¼çš„é¡¹ç›®
    """
    if len(df) == 0 or len(image_features) == 0:
        return pd.DataFrame()

    # è®¡ç®—æ¯ä¸ªæ–‡æœ¬å‘é‡ä¸æ‰€æœ‰å›¾åƒçš„ç›¸ä¼¼åº¦
    all_similarities = []
    for feature_vector in text_feature_vectors:
        if feature_vector is not None:
            similarities = cosine_similarity(feature_vector, image_features)
            all_similarities.append(similarities[0])

    if not all_similarities:
        return pd.DataFrame()

    # å¹³å‡æ‰€æœ‰ç›¸ä¼¼åº¦å¾—åˆ†
    avg_similarities = np.mean(all_similarities, axis=0)

    # è·å–æœ€ç›¸ä¼¼çš„top_kä¸ªç´¢å¼•
    top_indices = np.argsort(avg_similarities)[-top_k:][::-1]

    # è¿”å›æœ€ç›¸ä¼¼çš„è¡Œ
    return df.iloc[top_indices]


# ç”Ÿæˆç­–åˆ’ä¹¦å†…å®¹
def generate_proposal_content(user_input: str,
                            design_points: List[str],
                            relevant_projects: pd.DataFrame) -> str:
    """
    ç”Ÿæˆè®¾è®¡ç­–åˆ’ä¹¦å†…å®¹ - ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼qwen3-maxæ¨¡å‹
    """
    # æ„é€ è¾“å…¥ç»™å¤§æ¨¡å‹çš„prompt
    project_descriptions = []
    for _, row in relevant_projects.iterrows():
        project_descriptions.append(f"é¡¹ç›®ID: {row['project_id']}")

    prompt = f"""
ä½œä¸ºä¸€åä¸“ä¸šçš„å»ºç­‘è®¾è®¡å¸ˆAIåŠ©æ‰‹ï¼Œè¯·åŸºäºç”¨æˆ·è¾“å…¥çš„éœ€æ±‚ã€è®¾è®¡è¦ç‚¹åŠå‚è€ƒæ¡ˆä¾‹ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„å®Œæ•´ã€å†…å®¹ä¸“ä¸šçš„å»ºç­‘è®¾è®¡ç­–åˆ’ä¹¦ã€‚ç­–åˆ’ä¹¦åº”ä¸¥æ ¼éµå¾ªå»ºç­‘è¡Œä¸šçš„é€»è¾‘æ¡†æ¶ï¼Œçªå‡ºè®¾è®¡ç­–ç•¥ä¸æŠ€æœ¯å¯è¡Œæ€§ï¼Œå¹¶ä½“ç°å¯¹åœºåœ°ã€åŠŸèƒ½ã€ç©ºé—´åŠå¯æŒç»­æ€§çš„ç»¼åˆè€ƒé‡ï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{user_input}

è®¾è®¡è¦ç‚¹ï¼š
{chr(10).join(f'- {point}' for point in design_points)}

å‚è€ƒæ¡ˆä¾‹ï¼š
{chr(10).join(project_descriptions)}

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆç­–åˆ’ä¹¦ï¼š

# é¡¹ç›®æ¦‚è¿°
ç®€è¦æè¿°é¡¹ç›®èƒŒæ™¯å’Œç›®æ ‡
èƒŒæ™¯åˆ†æï¼šç»“åˆé¡¹ç›®åŒºä½ã€åœºåœ°æ¡ä»¶ï¼ˆåœ°å½¢ã€æ°”å€™ã€å‘¨è¾¹ç¯å¢ƒï¼‰ã€è§„åˆ’é™åˆ¶åŠä¸šä¸»éœ€æ±‚ï¼Œè¯´æ˜é¡¹ç›®ç«‹é¡¹çš„å¿…è¦æ€§ä¸æ ¸å¿ƒæŒ‘æˆ˜
ç›®æ ‡å®šä½ï¼šæ˜ç¡®é¡¹ç›®ç±»å‹ï¼ˆå¦‚æ–‡åŒ–ã€å•†ä¸šã€ä½å®…ç­‰ï¼‰ã€è§„æ¨¡ï¼ˆç”¨åœ°é¢ç§¯ã€å»ºç­‘é¢ç§¯ï¼‰åŠæ ¸å¿ƒç›®æ ‡ï¼ˆå¦‚æå‡åŒºåŸŸå½¢è±¡ã€æ»¡è¶³åŠŸèƒ½å¤åˆåŒ–éœ€æ±‚ç­‰ï¼‰

# è®¾è®¡ç†å¿µ
é˜è¿°è®¾è®¡ç†å¿µå’Œçµæ„Ÿæ¥æº
æ¦‚å¿µç”Ÿæˆï¼šé˜è¿°è®¾è®¡çµæ„Ÿçš„æ¥æºï¼ˆå¦‚åœ°åŸŸæ–‡è„‰ã€è‡ªç„¶æ„è±¡ã€ç¤¾ä¼šéœ€æ±‚ï¼‰ï¼Œå¹¶æç‚¼ä¸ºå¯è´¯ç©¿å…¨ç¨‹çš„è®¾è®¡ä¸»é¢˜ï¼ˆä¾‹å¦‚â€œæµåŠ¨çš„åº­é™¢â€â€œå…‰çš„å®¹å™¨â€ç­‰ï¼‰
ç­–ç•¥ç›¸åº”ï¼šè¯´æ˜è®¾è®¡å¦‚ä½•é€šè¿‡ç©ºé—´ç»„ç»‡ã€å½¢æ€æ„æˆã€ææ–™é€‰æ‹©ç­‰å…·ä½“æ‰‹æ®µå›åº”ç”¨åœ°ç‰¹å¾å’ŒåŠŸèƒ½éœ€æ±‚

# åŠŸèƒ½å¸ƒå±€
è¯¦ç»†è¯´æ˜å„åŠŸèƒ½åŒºåŸŸçš„è®¾è®¡
æ€»å¹³é¢è§„åˆ’ï¼šåˆ†æå»ºç­‘ä½“é‡ä¸åœºåœ°çš„å…³ç³»ï¼ŒåŒ…æ‹¬å‡ºå…¥å£è®¾ç½®ã€äº¤é€šæµçº¿ï¼ˆäººè½¦åˆ†æµï¼‰ã€æ™¯è§‚ç³»ç»ŸåŠä¸åŸå¸‚ç©ºé—´çš„è¡”æ¥
åŠŸèƒ½å¸ƒå±€ï¼šè¯¦ç»†åˆ—æ˜å„åŠŸèƒ½åŒºï¼ˆå¦‚å…¬å…±åŒºåŸŸã€æœåŠ¡ç©ºé—´ã€äº¤é€šæ ¸ï¼‰çš„é¢ç§¯åˆ†é…ã€å¹³é¢å¸ƒå±€åŠæµçº¿é€»è¾‘ï¼Œå¼ºè°ƒåŠŸèƒ½é—´çš„å…³è”ä¸éš”ç¦»

# ç©ºé—´ç‰¹è‰²
çªå‡ºé¡¹ç›®çš„ç‹¬ç‰¹è®¾è®¡å…ƒç´ 
ç«‹ä½“æ„æˆï¼šæè¿°å»ºç­‘å½¢æ€çš„ç”Ÿæˆé€»è¾‘ï¼ˆå¦‚ä½“å—åˆ‡å‰²ã€å åŠ ã€é•‚ç©ºï¼‰ï¼Œå¹¶åˆ†æç«‹é¢è®¾è®¡ï¼ˆæè´¨ã€è‚Œç†ã€è‰²å½©ï¼‰ä¸å†…éƒ¨åŠŸèƒ½çš„å¯¹åº”å…³ç³»
ç‰¹è‰²ç©ºé—´ï¼šé‡ç‚¹çªå‡ºæ ¸å¿ƒç©ºé—´ï¼ˆå¦‚ä¸­åº­ã€å±‹é¡¶èŠ±å›­ã€è¿‡æ¸¡ç©ºé—´ï¼‰çš„è®¾è®¡æ‰‹æ³•ï¼Œè¯´æ˜å…¶å¦‚ä½•å¢å¼ºä½“éªŒæ„Ÿä¸æ ‡è¯†æ€§


# æŠ€æœ¯å‚æ•°
åˆ—å‡ºå…³é”®æŠ€æœ¯æŒ‡æ ‡å’Œè§„æ ¼
å…³é”®æŒ‡æ ‡ï¼šåˆ—å‡ºå®¹ç§¯ç‡ã€å»ºç­‘å¯†åº¦ã€ç»¿åœ°ç‡ã€èŠ‚èƒ½ç‡ç­‰ç»æµæŠ€æœ¯æŒ‡æ ‡
ä¸“é¡¹è®¾è®¡ï¼šç®€è¿°ç»“æ„é€‰å‹ï¼ˆæ¡†æ¶/å‰ªåŠ›å¢™/é’¢ç»“æ„ï¼‰ã€ä¸»è¦ææ–™ï¼ˆå¦‚é¢„åˆ¶æ··å‡åœŸã€Low-Eç»ç’ƒï¼‰åŠè®¾å¤‡ç³»ç»Ÿï¼ˆæš–é€šã€æ¶ˆé˜²ã€æ™ºèƒ½åŒ–ï¼‰çš„åˆæ­¥æ–¹æ¡ˆ

# å¯æŒç»­æ€§è®¾è®¡
è¯´æ˜ç¯ä¿å’Œå¯æŒç»­æ€§æªæ–½
ç»¿è‰²æŠ€æœ¯ï¼šè¯´æ˜è¢«åŠ¨å¼è®¾è®¡ï¼ˆå¦‚è‡ªç„¶é€šé£ã€é®é˜³ï¼‰ä¸ä¸»åŠ¨æŠ€æœ¯ï¼ˆå¦‚å¤ªé˜³èƒ½å…‰ä¼ã€é›¨æ°´å›æ”¶ï¼‰çš„ç»“åˆæ–¹å¼
ç¯å¢ƒèåˆï¼šå¼ºè°ƒè®¾è®¡åœ¨ç”Ÿæ€ä¿æŠ¤ï¼ˆå¦‚æ¤è¢«ä¿ç•™ã€å¾®æ°”å€™è°ƒèŠ‚ï¼‰ä¸ä½ç¢³è¿ç»´æ–¹é¢çš„å…·ä½“æªæ–½

# æ•ˆæœé¢„æœŸ
æè¿°å»ºæˆåçš„æ•ˆæœå’Œå½±å“
ç©ºé—´æ•ˆæœï¼šæè¿°å»ºæˆåé¢„æœŸçš„ç©ºé—´æ°›å›´ã€ä½¿ç”¨æ•ˆç‡åŠäººæ–‡ä»·å€¼
ç¤¾ä¼šåŠç»æµå½±å“ï¼šåˆ†æé¡¹ç›®å¯¹åŒºåŸŸå‘å±•çš„è´¡çŒ®ï¼ˆå¦‚æå‡å…¬å…±æ€§ã€æ¿€å‘å•†ä¸šæ´»åŠ›ï¼‰ï¼Œå¹¶å¯é™„ç®€è¦æŠ•èµ„ä¼°ç®—

è¯·ç”¨ä¸“ä¸šè€Œæ˜“æ‡‚çš„å»ºç­‘å­¦è¯­è¨€æ’°å†™ï¼Œå­—æ•°åœ¨1500-3500å­—ä¹‹é—´ã€‚
"""

    # è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼qwen3-maxæ¨¡å‹
    try:
        import os
        from openai import OpenAI

        # ä»é…ç½®ä¸­è·å–APIå¯†é’¥ï¼ˆéœ€è¦åœ¨config.pyä¸­æ·»åŠ ï¼‰
        api_key = getattr(user_settings, 'qwen_api_key', None)
        if not api_key:
            raise ValueError("è¯·åœ¨config.pyä¸­é…ç½®qwen_api_key")

        client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

        completion = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å»ºç­‘è®¾è®¡å¸ˆAIåŠ©æ‰‹ï¼Œæ“…é•¿æ’°å†™å»ºç­‘è®¾è®¡ç­–åˆ’ä¹¦ã€‚"},
                {"role": "user", "content": prompt},
            ],
            stream=False  # ä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼Œä¾¿äºå¤„ç†
        )

        response = completion.choices[0].message.content
        return response

    except Exception as e:
        print(f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™: {e}")
        # å‡ºé”™æ—¶è¿”å›æ¨¡æ‹Ÿå†…å®¹
        mock_response = f"""
# é¡¹ç›®æ¦‚è¿°

æ ¹æ®æ‚¨çš„éœ€æ±‚â€”â€”{user_input}ï¼Œæˆ‘ä»¬æå‡ºä»¥ä¸‹è®¾è®¡æ–¹æ¡ˆã€‚è¯¥é¡¹ç›®æ—¨åœ¨åˆ›é€ ä¸€ä¸ªæ»¡è¶³åŠŸèƒ½éœ€æ±‚å¹¶å…·æœ‰ç‹¬ç‰¹è®¾è®¡æ„Ÿçš„å»ºç­‘ç©ºé—´ã€‚

# è®¾è®¡ç†å¿µ

è®¾è®¡çµæ„Ÿæ¥æºäºæ‚¨æå‡ºçš„éœ€æ±‚è¦ç‚¹ï¼Œç»“åˆç°ä»£å»ºç­‘è®¾è®¡ç†å¿µï¼Œæ‰“é€ åŠŸèƒ½å®Œå–„ã€ç¯å¢ƒå‹å¥½çš„å»ºç­‘ç©ºé—´ã€‚

# åŠŸèƒ½å¸ƒå±€

1. **ä¸»è¦åŠŸèƒ½åŒº**ï¼šæ ¹æ®éœ€æ±‚åˆç†è§„åˆ’å„åŠŸèƒ½åŒºåŸŸ
2. **è¾…åŠ©åŠŸèƒ½åŒº**ï¼šé…å¥—æœåŠ¡è®¾æ–½åŒºåŸŸ
3. **äº¤é€šæµçº¿**ï¼šä¼˜åŒ–äººæµå’Œç‰©æµç»„ç»‡

# ç©ºé—´ç‰¹è‰²

- ç»“åˆè®¾è®¡è¦ç‚¹åˆ›é€ ç‹¬ç‰¹ç©ºé—´ä½“éªŒ
- æ³¨é‡åŠŸèƒ½ä¸ç¾å­¦çš„å¹³è¡¡
- è€ƒè™‘æœªæ¥å‘å±•å’Œæ‰©å±•æ€§

# æŠ€æœ¯å‚æ•°

- æ ¹æ®éœ€æ±‚ç¡®å®šå…³é”®æŠ€æœ¯æŒ‡æ ‡
- ç¬¦åˆç›¸å…³å»ºç­‘è§„èŒƒå’Œæ ‡å‡†
- é‡‡ç”¨é€‚å®œçš„å»ºç­‘ææ–™å’ŒæŠ€æœ¯

# å¯æŒç»­æ€§è®¾è®¡

- èŠ‚èƒ½ç¯ä¿æªæ–½
- ç»¿è‰²å»ºç­‘æŠ€æœ¯åº”ç”¨
- å¯æŒç»­å‘å±•ç†å¿µè´¯å½»

# æ•ˆæœé¢„æœŸ

é¡¹ç›®å»ºæˆåå°†æ»¡è¶³ä½¿ç”¨éœ€æ±‚ï¼Œæˆä¸ºå…·æœ‰ç¤ºèŒƒæ„ä¹‰çš„å»ºç­‘ä½œå“ã€‚
        """
        return mock_response



# å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå®Œæ•´ç­–åˆ’æ–¹æ¡ˆ
def process_user_request(user_input: str, top_k: int = 5) -> Tuple[str, List[Tuple[str, str]]]:
    """
    å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼Œç”Ÿæˆå®Œæ•´çš„ç­–åˆ’æ–¹æ¡ˆ
    """
    if not user_input:
        return "è¯·è¾“å…¥æ‚¨çš„è®¾è®¡éœ€æ±‚", []

    # 1. æå–è®¾è®¡è¦ç‚¹
    design_points = extract_design_points(user_input)

    # 2. æå–å…³é”®è¯
    keywords = extract_keywords(design_points)

    # 3. è®¡ç®—å…³é”®è¯ç‰¹å¾å‘é‡
    text_feature_vectors = []
    for keyword in keywords[:5]:  # é™åˆ¶å…³é”®è¯æ•°é‡é¿å…è¿‡å¤šè®¡ç®—
        vector = compute_text_features(keyword)
        if vector is not None:
            text_feature_vectors.append(vector)

    # 4. æ£€ç´¢ç›¸å…³é¡¹ç›®
    if len(df) > 0 and len(image_features) > 0:
        relevant_projects = find_similar_items(text_feature_vectors, df, image_features, top_k)
    else:
        relevant_projects = pd.DataFrame()

    # 5. ç”Ÿæˆç­–åˆ’ä¹¦å†…å®¹
    proposal_content = generate_proposal_content(user_input, design_points, relevant_projects)

    # 6. å‡†å¤‡ç›¸å…³å›¾ç‰‡
    relevant_images = []
    if len(relevant_projects) > 0:
        for _, row in relevant_projects.iterrows():
            image_path = row['image_path']
            image_name = os.path.basename(image_path)
            project_id = row['project_id']
            full_image_path = os.path.join(
                user_settings.archdaily_projects_dir,
                project_id,
                "image_gallery/large",
                image_name
            )
            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if os.path.exists(full_image_path):
                relevant_images.append((full_image_path, project_id))
            else:
                # å¦‚æœç‰¹å®šå›¾ç‰‡ä¸å­˜åœ¨ï¼Œä½¿ç”¨å ä½ç¬¦
                relevant_images.append(("https://via.placeholder.com/300x200?text=Project+" + project_id, project_id))
    else:
        # å¦‚æœæ²¡æœ‰ç›¸å…³é¡¹ç›®ï¼Œæ·»åŠ å ä½ç¬¦å›¾ç‰‡
        for i in range(min(3, top_k)):
            relevant_images.append((
                "https://via.placeholder.com/300x200?text=Sample+Design",
                f"sample_{i}"
            ))

    return proposal_content, relevant_images


# Gradioç•Œé¢
with gr.Blocks(title="æ™ºèƒ½å»ºç­‘ç­–åˆ’Agent") as iface:
    gr.Markdown("# ğŸ›ï¸ æ™ºèƒ½å»ºç­‘ç­–åˆ’Agent")
    gr.Markdown("è¾“å…¥æ‚¨çš„å»ºç­‘è®¾è®¡éœ€æ±‚ï¼ŒAIå°†è‡ªåŠ¨ç”Ÿæˆç­–åˆ’æ–¹æ¡ˆå¹¶æ¨èç›¸å…³æ¡ˆä¾‹")

    with gr.Row():
        with gr.Column(scale=1):
            user_input = gr.Textbox(
                label="ğŸ“ è¯·è¾“å…¥æ‚¨çš„è®¾è®¡éœ€æ±‚",
                placeholder="ä¾‹å¦‚ï¼šæˆ‘è¦åœ¨å±±è„šä¸‹å»ºä¸€åº§24ä¸ªç­çš„å°å­¦...",
                lines=3
            )

            with gr.Accordion("âš™ï¸ é«˜çº§å‚æ•°", open=False):
                top_k_slider = gr.Slider(
                    1, 10, value=5, step=1,
                    label="æ¨èæ¡ˆä¾‹æ•°é‡"
                )

            submit_btn = gr.Button(
                "ğŸš€ ç”Ÿæˆç­–åˆ’æ–¹æ¡ˆ",
                variant="primary"
            )

            gr.Examples(
                examples=[
                    "æˆ‘è¦åœ¨å±±è„šä¸‹å»ºä¸€åº§24ä¸ªç­çš„å°å­¦",
                    "è®¾è®¡ä¸€ä¸ªæµ·è¾¹çš„ç°ä»£åŒ–ç¾æœ¯é¦†",
                    "åœ¨åŸå¸‚ä¸­å¿ƒå»ºé€ ä¸€ä¸ªç»¿è‰²åŠå…¬å¤§æ¥¼",
                    "è®¾è®¡ä¸€æ‰€å¯å®¹çº³500äººçš„å¯„å®¿åˆ¶é«˜ä¸­"
                ],
                inputs=user_input,
                label="ğŸ’¡ ç¤ºä¾‹è¾“å…¥"
            )

        with gr.Column(scale=2):
            output_text = gr.Markdown(label="ğŸ“‹ ç­–åˆ’æ–¹æ¡ˆ")
            output_gallery = gr.Gallery(
                label="ğŸ–¼ï¸ ç›¸å…³è®¾è®¡æ¡ˆä¾‹",
                columns=3,
                rows=2,
                object_fit="cover",
                height="auto"
            )


    # å¤„ç†å‡½æ•°
    def handle_request(user_input_text, k_value):
        return process_user_request(user_input_text, k_value)


    # ç»‘å®šäº‹ä»¶
    submit_btn.click(
        handle_request,
        inputs=[user_input, top_k_slider],
        outputs=[output_text, output_gallery]
    )

    # å›è½¦é”®è§¦å‘
    user_input.submit(
        handle_request,
        inputs=[user_input, top_k_slider],
        outputs=[output_text, output_gallery]
    )

if __name__ == "__main__":
    iface.launch(share=True)