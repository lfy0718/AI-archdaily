# -*- coding: utf-8 -*-
# @Author  : Xinruo Wang
# @Time    : 10/25/2025 8:40 PM
# @Function: AI planningåç«¯
"""
æ™ºèƒ½è®¾è®¡ç­–åˆ’ç³»ç»Ÿ - å·¥å…·å‡½æ•°æ¨¡å—
åŠŸèƒ½ï¼šMongoDBå‘é‡æ£€ç´¢ã€å›¾ç‰‡æ£€ç´¢ã€Qwen APIè°ƒç”¨ã€ç­–åˆ’ç”Ÿæˆ
"""
import os
import sys
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional
from sklearn.metrics.pairwise import cosine_similarity
from pymongo import MongoClient
from openai import OpenAI
from datetime import datetime

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
#sys.path.append('.')


class VectorSearchManager:
    """
    MongoDBå‘é‡æ£€ç´¢ç®¡ç†å™¨
    è´Ÿè´£ï¼šæ–‡æœ¬å‘é‡åŒ– + MongoDB Vector Search
    """

    def __init__(self, config):
        """
        åˆå§‹åŒ–å‘é‡æ£€ç´¢ç®¡ç†å™¨

        å‚æ•°ï¼š
            config: é…ç½®å¯¹è±¡ï¼ˆæ¥è‡ªconfig.pyçš„user_settingsï¼‰
        """
        self.config = config
        print(f"\n{'=' * 60}")
        print(f"ğŸ”Œ æ­£åœ¨åˆå§‹åŒ–å‘é‡æ£€ç´¢ç³»ç»Ÿ...")
        print(f"{'=' * 60}")

        # è¿æ¥MongoDB
        try:
            self.mongo_client = MongoClient(
                config.mongodb_host,
                serverSelectionTimeoutMS=5000
            )
            self.mongo_client.server_info()  # æµ‹è¯•è¿æ¥

            self.db = self.mongo_client[config.mongodb_archdaily_db_name]
            # åªéœ€è¦content_embeddingé›†åˆ
            self.embedding_collection = self.db['content_embedding']

            # ç»Ÿè®¡æ•°æ®
            embedding_count = self.embedding_collection.count_documents({})

            print(f"âœ… MongoDBè¿æ¥æˆåŠŸï¼")
            print(f"   æ•°æ®åº“: {config.mongodb_archdaily_db_name}")
            print(f"   å‘é‡æ•°æ®æ•°: {embedding_count}")

        except Exception as e:
            print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
            raise

        # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯
        self.qwen_client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        print(f"âœ… Qwenå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"{'=' * 60}\n")

    def get_text_embedding(self, text: str) -> List[float]:
        """
        ä½¿ç”¨Qwenå°†æ–‡æœ¬è½¬ä¸º1536ç»´å‘é‡

        å‚æ•°ï¼š
            text: è¦å‘é‡åŒ–çš„æ–‡æœ¬

        è¿”å›ï¼š
            1536ç»´å‘é‡åˆ—è¡¨
        """
        try:
            response = self.qwen_client.embeddings.create(
                model="text-embedding-v3",
                input=text
            )
            embedding = response.data[0].embedding
            print(f"   âœ“ å‘é‡åŒ–: {text[:50]}... â†’ {len(embedding)}ç»´")
            return embedding

        except Exception as e:
            print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
            return []

    def vector_search(self, query_text: str, top_k: int = 5) -> List[Dict]:
        """
        ã€æ ¸å¿ƒæ–¹æ³•ã€‘MongoDBå‘é‡æ£€ç´¢

        å·¥ä½œæµç¨‹ï¼š
        1. å°†æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–ï¼ˆQwen Embeddingï¼‰
        2. åœ¨MongoDBä¸­è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
        3. è¿”å›æœ€ç›¸å…³çš„æ–‡æœ¬å—

        å‚æ•°ï¼š
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡

        è¿”å›ï¼š
            åŒ¹é…çš„æ–‡æ¡£åˆ—è¡¨
        """
        print(f"\nğŸ“Š MongoDBå‘é‡æ£€ç´¢")
        print(f"   æŸ¥è¯¢: \"{query_text}\"")
        print(f"   ç›®æ ‡æ•°é‡: {top_k}")

        # Step 1: å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
        query_embedding = self.get_text_embedding(query_text)
        if not query_embedding:
            print(f"âŒ æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–å¤±è´¥")
            return []

        # Step 2: æ„å»ºMongoDB Vector SearchèšåˆæŸ¥è¯¢
        pipeline = [
            {
                "$vectorSearch": {
                    "index": self.config.vector_search_index_name,   # å‘é‡ç´¢å¼•åç§°
                    "path": "embedding",  # å‘é‡å­—æ®µå
                    "queryVector": query_embedding,
                    "numCandidates": top_k * 10,
                    "limit": top_k
                }
            },
            {
                "$project": {
                    "project_id": 1,
                    "text_content": 1,
                    "text_idx": 1,
                    "chunk_idx": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]

        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            results = list(self.embedding_collection.aggregate(pipeline))
            print(f"âœ… æ‰¾åˆ° {len(results)} æ¡ç›¸å…³ç»“æœ")

            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for doc in results:
                formatted_results.append({
                    'project_id': doc.get('project_id'),
                    'text_content': doc.get('text_content', ''),
                    'text_idx': doc.get('text_idx'),
                    'chunk_idx': doc.get('chunk_idx'),
                    'similarity_score': doc.get('score', 0)
                })
                print(f"   - é¡¹ç›®{doc.get('project_id')} | "
                      f"åˆ†æ•°:{doc.get('score', 0):.3f} | "
                      f"{doc.get('text_content', '')[:50]}...")

            return formatted_results

        except Exception as e:
            print(f"âŒ å‘é‡æ£€ç´¢å¤±è´¥: {e}")
            print(f"   æç¤º: è¯·ç¡®ä¿å·²åœ¨MongoDBä¸­åˆ›å»ºå‘é‡æœç´¢ç´¢å¼•")
            print(f"   ç´¢å¼•åç§°: vector_index")
            print(f"   ç´¢å¼•å­—æ®µ: embedding (1536ç»´)")
            return []


class ImageSearchManager:
    """
    å›¾ç‰‡æ£€ç´¢ç®¡ç†å™¨ï¼ˆä½¿ç”¨CN-CLIPï¼‰
    è´Ÿè´£ï¼šæ ¹æ®å…³é”®è¯æ£€ç´¢ç›¸ä¼¼å›¾ç‰‡
    """

    def __init__(self, config):
        """
        åˆå§‹åŒ–å›¾ç‰‡æ£€ç´¢ç®¡ç†å™¨

        å‚æ•°ï¼š
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        print(f"\n{'=' * 60}")
        print(f"ğŸ–¼ï¸  æ­£åœ¨åˆå§‹åŒ–å›¾ç‰‡æ£€ç´¢ç³»ç»Ÿ...")
        print(f"{'=' * 60}")

        try:
            # åŠ è½½å›¾åƒç‰¹å¾æ•°æ®åº“
            pkl_path = 'results/database/image_database.pkl'
            self.image_df = pd.read_pickle(pkl_path)
            self.image_df = self.image_df[
                self.image_df['features'].apply(lambda x: isinstance(x, np.ndarray))
            ]
            self.image_df['features'] = self.image_df['features'].apply(
                lambda x: x.squeeze()
            )
            self.image_features = np.stack(self.image_df['features'].values)

            print(f"âœ… å›¾åƒæ•°æ®åº“åŠ è½½æˆåŠŸï¼")
            print(f"   å›¾ç‰‡æ•°: {len(self.image_df)}")
            print(f"   ç‰¹å¾ç»´åº¦: {self.image_features.shape}")
        except Exception as e:
            print(f"âŒ å›¾åƒæ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
            raise

        print(f"{'=' * 60}\n")

    def search_similar_images(self, keywords: List[str], top_k: int = 6) -> List[Dict]:
        """
        æ ¹æ®å…³é”®è¯æ£€ç´¢ç›¸ä¼¼å›¾åƒ

        å‚æ•°ï¼š
            keywords: å…³é”®è¯åˆ—è¡¨
            top_k: è¿”å›å›¾ç‰‡æ•°é‡

        è¿”å›ï¼š
            åŒ…å«å›¾ç‰‡è·¯å¾„å’Œé¡¹ç›®IDçš„å­—å…¸åˆ—è¡¨
        """
        # å¯¼å…¥cn_clip_api
        try:
            from apis import cn_clip_api
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥cn_clip_api: {e}")
            return []

        # åˆå¹¶å…³é”®è¯
        query_text = " ".join(keywords)
        print(f"\nğŸ” å›¾ç‰‡æ£€ç´¢")
        print(f"   æŸ¥è¯¢: \"{query_text}\"")

        try:
            # ä½¿ç”¨CN-CLIPæå–æ–‡æœ¬ç‰¹å¾
            text_features = cn_clip_api.get_text_features(query_text)

            if text_features.ndim == 1:
                text_features = text_features.reshape(1, -1)

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = cosine_similarity(text_features, self.image_features)
            top_indices = np.argsort(similarities[0])[-top_k:][::-1]

            # æ„å»ºç»“æœ
            results = []
            for idx in top_indices:
                row = self.image_df.iloc[idx]
                image_path = self._get_full_image_path(row)

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(image_path):
                    print(f"âš ï¸  å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
                    continue

                results.append({
                    'image_path': image_path,
                    'project_id': row['project_id'],
                    'similarity': float(similarities[0][idx])
                })

            print(f"âœ… æ‰¾åˆ° {len(results)} å¼ ç›¸ä¼¼å›¾ç‰‡")
            return results

        except Exception as e:
            print(f"âŒ å›¾ç‰‡æ£€ç´¢å¤±è´¥: {e}")
            return []

    def _get_full_image_path(self, row) -> str:
        """è·å–å›¾ç‰‡å®Œæ•´è·¯å¾„"""
        image_name = os.path.basename(row['image_path'])
        return os.path.join(
            self.config.archdaily_projects_dir,
            row['project_id'],
            "image_gallery/large",
            image_name
        )


class QwenAPIClient:
    """Qwen3 APIå®¢æˆ·ç«¯ - è´Ÿè´£æ‰€æœ‰å¤§æ¨¡å‹å¯¹è¯"""

   def __init__(self):
    """åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯"""
    try:
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY") or "sk-05dba08497cf465f9e4b9ca1a25bb973",  # âœ… æ·»åŠ é»˜è®¤å€¼
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = "qwen-plus"
        print(f"âœ… Qwenå¯¹è¯æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ ({self.model})")
    except Exception as e:
        print(f"âŒ Qwenå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        raise


    def _call_api(self, prompt: str, system_prompt: str = None,
                  temperature: float = 0.7) -> str:
        """è°ƒç”¨Qwen API"""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature
            )
            return completion.choices[0].message.content
        except Exception as e:
            print(f"âŒ Qwen APIè°ƒç”¨å¤±è´¥: {e}")
            return ""

    def extract_keywords(self, user_query: str) -> List[str]:
        """ã€æ­¥éª¤1ã€‘æå–å…³é”®è¯"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ æ­¥éª¤1: æå–å…³é”®è¯")
        print(f"{'=' * 60}")

        prompt = f"""
è¯·ä»ä»¥ä¸‹å»ºç­‘éœ€æ±‚ä¸­æå–3-5ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼Œç”¨äºæ•°æ®åº“æ£€ç´¢ã€‚

è¦æ±‚ï¼š
1. æå–å»ºç­‘ç±»å‹ã€åœ°ç†ç‰¹å¾ã€è§„æ¨¡ã€åŠŸèƒ½ç­‰æ ¸å¿ƒä¿¡æ¯
2. å…³é”®è¯è¦å…·ä½“ã€å‡†ç¡®
3. åªè¿”å›å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–è§£é‡Š

ç”¨æˆ·éœ€æ±‚ï¼š{user_query}

å…³é”®è¯ï¼š"""

        response = self._call_api(prompt, temperature=0.3)
        keywords = [kw.strip() for kw in response.split(',') if kw.strip()]
        print(f"ğŸ”‘ æå–åˆ°çš„å…³é”®è¯: {keywords}")
        print(f"{'=' * 60}\n")
        return keywords

    def generate_design_points(self, user_query: str, context: str) -> str:
        """ã€æ­¥éª¤2ã€‘ç”Ÿæˆè®¾è®¡è¦ç‚¹"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ æ­¥éª¤2: ç”Ÿæˆè®¾è®¡è¦ç‚¹")
        print(f"{'=' * 60}")

        system_prompt = "ä½ æ˜¯ä¸€ä½èµ„æ·±å»ºç­‘è®¾è®¡é¡¾é—®ï¼Œæ“…é•¿åˆ†æå»ºç­‘éœ€æ±‚å¹¶æå‡ºä¸“ä¸šå»ºè®®ã€‚"

        prompt = f"""
æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·çš„å»ºç­‘éœ€æ±‚æä¾›5-8ä¸ªæ ¸å¿ƒè®¾è®¡è¦ç‚¹ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š
{user_query}

å‚è€ƒæ¡ˆä¾‹ï¼ˆæ¥è‡ªæ•°æ®åº“æ£€ç´¢ï¼‰ï¼š
{context if context else "æš‚æ— å‚è€ƒæ¡ˆä¾‹"}

è¦æ±‚ï¼š
1. æ¯ä¸ªè¦ç‚¹å•ç‹¬ä¸€è¡Œï¼Œæ ¼å¼ä¸º"æ•°å­—. è¦ç‚¹æ ‡é¢˜: ç®€è¦è¯´æ˜"
2. è¦ç‚¹åº”å…·ä½“ã€å¯æ“ä½œ
3. åŒ…å«ï¼šé€‰å€ã€åŠŸèƒ½å¸ƒå±€ã€ç¯å¢ƒé€‚åº”ã€ç¾å­¦é£æ ¼ç­‰
4. æ¯ä¸ªè¦ç‚¹30-50å­—

è®¾è®¡è¦ç‚¹ï¼š"""

        response = self._call_api(prompt, system_prompt, temperature=0.7)
        print(f"ğŸ“ ç”Ÿæˆçš„è®¾è®¡è¦ç‚¹:\n{response}")
        print(f"{'=' * 60}\n")
        return response

    def extract_keywords_from_points(self, design_points: str) -> List[str]:
        """ã€æ­¥éª¤3ã€‘æå–è§†è§‰å…³é”®è¯"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ æ­¥éª¤3: æå–è§†è§‰å…³é”®è¯")
        print(f"{'=' * 60}")

        prompt = f"""
ä»ä»¥ä¸‹è®¾è®¡è¦ç‚¹ä¸­æå–5-8ä¸ª**è§†è§‰ç›¸å…³**çš„å…³é”®è¯ï¼Œç”¨äºå»ºç­‘å›¾ç‰‡æ£€ç´¢ã€‚

è¦æ±‚ï¼š
1. å…³é”®è¯åº”è¯¥æ˜¯å…·ä½“çš„å»ºç­‘å…ƒç´ ã€é£æ ¼ç‰¹å¾
2. é€‚åˆç”¨äºå›¾ç‰‡æœç´¢ï¼ˆå¦‚"å¡å±‹é¡¶"ã€"åº­é™¢"ã€"æœ¨ç»“æ„"ï¼‰
3. åªè¿”å›å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”

è®¾è®¡è¦ç‚¹ï¼š
{design_points}

å…³é”®è¯ï¼š"""

        response = self._call_api(prompt, temperature=0.3)
        keywords = [kw.strip() for kw in response.split(',') if kw.strip()]
        print(f"ğŸ¨ è§†è§‰å…³é”®è¯: {keywords}")
        print(f"{'=' * 60}\n")
        return keywords

    def generate_final_report(self, user_query: str, design_points: str,
                              images: List[Dict], reference_cases: str = "") -> str:
        """ã€æ­¥éª¤4ã€‘ç”Ÿæˆæœ€ç»ˆç­–åˆ’ä¹¦"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ æ­¥éª¤4: ç”Ÿæˆç­–åˆ’ä¹¦")
        print(f"{'=' * 60}")

        image_info = "\n".join([
            f"- å›¾ç‰‡{i + 1}: é¡¹ç›®{img['project_id']} (ç›¸ä¼¼åº¦: {img['similarity']:.2f})"
            for i, img in enumerate(images)
        ])

        system_prompt = "ä½ æ˜¯ä¸€ä½èµ„æ·±å»ºç­‘è®¾è®¡ç­–åˆ’å¸ˆï¼Œæ“…é•¿æ’°å†™ä¸“ä¸šçš„è®¾è®¡ç­–åˆ’ä¹¦ã€‚"

        prompt = f"""
è¯·æ’°å†™ä¸€ä»½ä¸“ä¸šçš„å»ºç­‘è®¾è®¡ç­–åˆ’ä¹¦ã€‚

## ç”¨æˆ·éœ€æ±‚
{user_query}

## è®¾è®¡è¦ç‚¹
{design_points}

## å‚è€ƒæ¡ˆä¾‹
{reference_cases if reference_cases else "ï¼ˆåŸºäºä¸“ä¸šçŸ¥è¯†ï¼‰"}

## å¯ç”¨å›¾ç‰‡
{image_info}

## æ’°å†™è¦æ±‚
1. **æ ¼å¼**: Markdownï¼ŒåŒ…å«æ ‡é¢˜å’Œæ®µè½
2. **ç»“æ„**: é¡¹ç›®æ¦‚è¿° â†’ è®¾è®¡ç†å¿µ â†’ è®¾è®¡è¦ç‚¹è¯¦è¿° â†’ å‚è€ƒæ¡ˆä¾‹
3. **æ’å›¾**: åœ¨åˆé€‚ä½ç½®æ’å…¥ [IMAGE_0]ã€[IMAGE_1]... æœ€å¤š{len(images)}å¼ 
4. **å­—æ•°**: 800-1200å­—
5. **é£æ ¼**: ä¸“ä¸šã€ç®€æ´ã€æœ‰æ´å¯ŸåŠ›

å¼€å§‹æ’°å†™ï¼š"""

        response = self._call_api(prompt, system_prompt, temperature=0.8)
        print(f"ğŸ“„ ç­–åˆ’ä¹¦ç”Ÿæˆå®Œæˆ (çº¦ {len(response)} å­—)")
        print(f"{'=' * 60}\n")
        return response


class PlanningAgent:
    """ç­–åˆ’Agent - åè°ƒæ•´ä¸ªæµç¨‹"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–ç­–åˆ’Agent

        å‚æ•°ï¼š
            config: é…ç½®å¯¹è±¡ï¼ˆæ¥è‡ªconfig.pyçš„user_settingsï¼‰
        """
        print(f"\n{'#' * 60}")
        print(f"ğŸš€ åˆå§‹åŒ–æ™ºèƒ½ç­–åˆ’Agent")
        print(f"{'#' * 60}\n")

        self.vector_search = VectorSearchManager(config)
        self.image_search = ImageSearchManager(config)
        self.qwen_client = QwenAPIClient()

        print(f"âœ… Agentåˆå§‹åŒ–å®Œæˆï¼\n")

    def run(self, user_query: str) -> Tuple[str, List[str]]:
        """
        æ‰§è¡Œå®Œæ•´ç­–åˆ’æµç¨‹

        å‚æ•°ï¼š
            user_query: ç”¨æˆ·è¾“å…¥çš„å»ºç­‘éœ€æ±‚

        è¿”å›ï¼š
            (ç­–åˆ’ä¹¦Markdown, å›¾ç‰‡è·¯å¾„åˆ—è¡¨)
        """
        print(f"\n{'#' * 60}")
        print(f"ğŸ¯ å¼€å§‹å¤„ç†ç”¨æˆ·éœ€æ±‚")
        print(f"   éœ€æ±‚: {user_query}")
        print(f"{'#' * 60}\n")

        try:
            # Step 1: æå–å…³é”®è¯
            keywords = self.qwen_client.extract_keywords(user_query)
            if not keywords:
                return "âŒ å…³é”®è¯æå–å¤±è´¥", []

            # Step 2: MongoDBå‘é‡æ£€ç´¢ï¼ˆæ ¸å¿ƒï¼ï¼‰
            query_text = " ".join(keywords)
            search_results = self.vector_search.vector_search(query_text, top_k=5)

            # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
            reference_cases = self._format_search_results(search_results)

            # Step 3: ç”Ÿæˆè®¾è®¡è¦ç‚¹
            design_points = self.qwen_client.generate_design_points(
                user_query, reference_cases
            )
            if not design_points:
                return "âŒ è®¾è®¡è¦ç‚¹ç”Ÿæˆå¤±è´¥", []

            # Step 4: æå–è§†è§‰å…³é”®è¯
            image_keywords = self.qwen_client.extract_keywords_from_points(design_points)
            if not image_keywords:
                image_keywords = keywords

            # Step 5: å›¾ç‰‡æ£€ç´¢
            images = self.image_search.search_similar_images(image_keywords, top_k=6)

            # Step 6: ç”Ÿæˆç­–åˆ’ä¹¦
            report = self.qwen_client.generate_final_report(
                user_query, design_points, images, reference_cases
            )

            # Step 7: æ’å…¥å›¾ç‰‡
            report_with_images, image_paths = self._insert_images(report, images)

            print(f"\n{'#' * 60}")
            print(f"âœ… ç­–åˆ’å®Œæˆï¼")
            print(f"   ç­–åˆ’ä¹¦é•¿åº¦: {len(report_with_images)} å­—ç¬¦")
            print(f"   æ’å…¥å›¾ç‰‡: {len(image_paths)} å¼ ")
            print(f"{'#' * 60}\n")

            return report_with_images, image_paths

        except Exception as e:
            error_msg = f"âŒ å¤„ç†å‡ºé”™: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return error_msg, []

    def _format_search_results(self, results: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æœ"""
        if not results:
            return ""

        formatted = []
        for i, doc in enumerate(results[:3], 1):
            text = doc.get('text_content', '')
            if len(text) > 200:
                text = text[:200] + "..."
            formatted.append(
                f"å‚è€ƒæ¡ˆä¾‹{i} (é¡¹ç›®{doc.get('project_id')}): {text}"
            )

        return "\n\n".join(formatted)

    def _insert_images(self, report: str, images: List[Dict]) -> Tuple[str, List[str]]:
        """æ’å…¥å›¾ç‰‡"""
        image_paths = [img['image_path'] for img in images]

        for i, img in enumerate(images):
            placeholder = f"[IMAGE_{i}]"
            markdown_image = f"\n\n![å‚è€ƒæ¡ˆä¾‹{i + 1}]({img['image_path']})\n"
            markdown_image += f"*å‚è€ƒæ¡ˆä¾‹ {i + 1} - é¡¹ç›®{img['project_id']} (ç›¸ä¼¼åº¦: {img['similarity']:.2f})*\n\n"
            report = report.replace(placeholder, markdown_image)

        return report, image_paths