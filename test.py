import requests
import time
import os
from bs4 import BeautifulSoup
from fake_useragent import UserAgent

# ç›®æ ‡ URL
ARCHDAILY_SEARCH_URL = "https://www.archdaily.com/search/projects?p="

# ä¼ªé€  User-Agent
ua = UserAgent()
HEADERS = {"User-Agent": ua.random}

# å›¾ç‰‡å­˜å‚¨ç›®å½•
IMG_FOLDER = "archdaily_images"
os.makedirs(IMG_FOLDER, exist_ok=True)


def get_project_links():
    """è·å– ArchDaily ä¸Šçš„ 3 ä¸ªå»ºç­‘é¡¹ç›®é“¾æ¥"""
    url = ARCHDAILY_SEARCH_URL + "1"  # åªçˆ¬å–ç¬¬ 1 é¡µ
    response = requests.get(url, headers=HEADERS)

    if response.status_code != 200:
        print("âŒ æ— æ³•è®¿é—® ArchDaily")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    project_elements = soup.find_all("div", class_="afd-search-list__item")
    project_links = ["https://www.archdaily.com" + item.find("a")["href"] for item in project_elements if item.find("a")]

    return project_links[:3]  # å–å‰ 3 ä¸ªé¡¹ç›®


def scrape_project_details(project_url):
    """çˆ¬å–å»ºç­‘é¡¹ç›®çš„è¯¦æƒ…å’Œå›¾ç‰‡"""
    response = requests.get(project_url, headers=HEADERS)

    if response.status_code != 200:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {project_url}")
        return None

    soup = BeautifulSoup(response.text, "html.parser")

    # è·å–å»ºç­‘ä¿¡æ¯
    title = soup.find("h1", class_="afd-title-big").text.strip() if soup.find("h1", class_="afd-title-big") else "æœªçŸ¥"
    architect = soup.find("strong", class_="afd-project-lead__link").text.strip() if soup.find("strong", class_="afd-project-lead__link") else "æœªçŸ¥"
    description = " ".join([p.text.strip() for p in soup.find_all("p")])[:500]  # å–å‰ 500 ä¸ªå­—ç¬¦

    print(f"ğŸ“Œ é¡¹ç›®: {title}")
    print(f"ğŸ— å»ºç­‘å¸ˆ: {architect}")
    print(f"ğŸ“– ç®€ä»‹: {description[:100]}...")

    # è·å–å›¾ç‰‡é“¾æ¥
    img_tags = soup.find_all("img", class_="picture--content__img")
    img_urls = [img["src"] for img in img_tags if "src" in img.attrs]

    for img_url in img_urls:
        download_image(img_url, title)

    return {"title": title, "architect": architect, "description": description, "url": project_url, "images": img_urls}


def download_image(img_url, title):
    """ä¸‹è½½å»ºç­‘å›¾ç‰‡"""
    try:
        response = requests.get(img_url, headers=HEADERS, stream=True)
        if response.status_code == 200:
            filename = f"{IMG_FOLDER}/{title.replace(' ', '_')}.jpg"
            with open(filename, "wb") as file:
                for chunk in response.iter_content(1024):
                    file.write(chunk)
            print(f"âœ… ä¸‹è½½å›¾ç‰‡: {filename}")
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")


def main():
    """çˆ¬å– 3 ä¸ªå»ºç­‘é¡¹ç›®"""
    project_links = get_project_links()

    for project_url in project_links:
        scrape_project_details(project_url)
        time.sleep(2)  # é¿å…è¢«å°


if __name__ == "__main__":
    main()
